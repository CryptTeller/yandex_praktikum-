{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ivan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import xgboost as xgb\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest , chi2\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV , GridSearchCV\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import os\n",
    "import re\n",
    "import spacy\n",
    "from spacy.lemmatizer import Lemmatizer\n",
    "from spacy.lookups import Lookups\n",
    "from joblib import dump, load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Места расположения папок с моделью BERT и исходными данными\n",
    "DATA_PATH = \"C:\\\\Users\\ivan\\\\YandexDisk\\\\DS\\\\Project_11\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = pd.read_csv(os.path.join(DATA_PATH,'toxic_comments.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество строк датасета 159571\n"
     ]
    }
   ],
   "source": [
    "print('Количество строк датасета', len(df_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation\n",
      "Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27 \n",
      "\n",
      "Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Проверим по некоторым сторокам какой там текст\n",
    "print(df_text['text'][0],'\\n')\n",
    "print(df_text['text'][2],'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем библиотеку\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "# Делаем из текста леммы\n",
    "def text_prepare(row):\n",
    "    # выделяем текст из строки, преобразуем, выделяем лемму, удаляем лишние символы\n",
    "    text = row['text']   \n",
    "    doc = nlp(text)   \n",
    "    out_text= \" \".join([token.lemma_ for token in doc ])      \n",
    "    return re.sub('[^a-zA-Z]', ' ', out_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Векторизуем токены\n",
    "def vectorizer_func(data):\n",
    "    # Выделяем корпус с леммами\n",
    "    corpus = np.array(data.apply(text_prepare , axis=1)).astype('U')\n",
    "    \n",
    "    stopwords = set(nltk_stopwords.words('english'))\n",
    "    target = data['toxic']\n",
    "    \n",
    "    # Делим корпус текста на train и test\n",
    "    X_train , X_test , y_train , y_test  = train_test_split(corpus , target , test_size = 0.4 , random_state = 12)    \n",
    "    \n",
    "    \n",
    "    vectorizer = TfidfVectorizer(stop_words = stopwords , ngram_range=(1,3))\n",
    "    vect_tf_idf_train = vectorizer.fit_transform(X_train)\n",
    "    vect_tf_idf_test = vectorizer.transform(X_test)\n",
    "    \n",
    "    # Возвращаем словарь с признаками и таргетами\n",
    "    return {'X_train':vect_tf_idf_train, \n",
    "            'X_test': vect_tf_idf_test , \n",
    "            'y_train': y_train , \n",
    "            'y_test': y_test }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Записываем признаки и таргеты в переменные\n",
    "train_dict = vectorizer_func(df_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_dict['X_train']\n",
    "X_test = train_dict['X_test']\n",
    "y_train = train_dict['y_train']\n",
    "y_test = train_dict['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((95742, 4077383), (63829, 4077383), (95742,), (63829,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Загружаем модель и считаем f1 на кроссвалидации\n",
    "lr_model = LogisticRegression(class_weight = 'balanced' ,  random_state = 12, C=1 , max_iter = 500)\n",
    "\n",
    "# Выбираем лучшие признаки\n",
    "selector = SelectKBest(chi2, k=50000)\n",
    "\n",
    "\n",
    "clf_selected = Pipeline([('selector' , selector) , ('lr_model' , lr_model)])\n",
    "scores = cross_val_score(clf_selected , X_train , y_train , scoring ='f1' , cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression Cross validation F1, default parameters: 0.7358689911305563\n"
     ]
    }
   ],
   "source": [
    "print('Logistic regression Cross validation F1, default parameters:', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 19min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr_model = LogisticRegression(solver='lbfgs', \n",
    "                             # tol=1e-2, \n",
    "                              max_iter=500,\n",
    "                              class_weight = 'balanced' ,\n",
    "                              random_state = 12)\n",
    "# параметры для поиска\n",
    "distributions = {'lr_model__C':range(10,32,2) ,\n",
    "                'selector__k':[50000 , 75000 , 100000]}\n",
    "\n",
    "# Выбираем лучшие признаки\n",
    "selector = SelectKBest(chi2)\n",
    "\n",
    "clf_selected = Pipeline([('selector' , selector) , ('lr_model' , lr_model)])\n",
    "\n",
    "clf = RandomizedSearchCV(clf_selected, distributions , random_state=12 , cv = 5 , scoring ='f1')\n",
    "search = clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры:\n",
      "{'selector__k': 50000, 'lr_model__C': 16}\n",
      "\n",
      "Лучший F1:\n",
      "0.7685908376712342\n"
     ]
    }
   ],
   "source": [
    "print(\"Лучшие параметры:\")\n",
    "print(search.best_params_ )\n",
    "print()\n",
    "\n",
    "print(\"Лучший F1:\")\n",
    "print(search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logistic_tuned.joblib']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Сохраняем лучшую модель  и параметры\n",
    "best_lr_model = search.best_estimator_\n",
    "\n",
    "best_lr_params = search.best_params_ \n",
    "\n",
    "dump(best_lr_model , 'logistic_tuned.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Записываем данные\n",
    "dtrain = xgb.DMatrix(X_train, label= y_train)\n",
    "dtest  = xgb.DMatrix(X_test, label= y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'max_depth': 5, 'learning_rate': 1 }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Загружаем модель , отбираем признаки\n",
    "xgb_model = xgb.XGBClassifier( random_state=12)\n",
    "selector = SelectKBest(chi2, k=10000)\n",
    "\n",
    "clf_selected = Pipeline([('selector', selector) , ('xgb_model' , xgb_model)])\n",
    "\n",
    "scores = cross_val_score(clf_selected , X_train , y_train , scoring ='f1' , cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Cross validation F1, default parameters: 0.7241948138006886\n"
     ]
    }
   ],
   "source": [
    "print('XGBoost Cross validation F1, default parameters:', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "[CV] xgb_model__n_estimators=200, xgb_model__max_depth=40, xgb_model__learning_rate=0.3, xgb_model__gamma=1.5, selector__k=85000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  xgb_model__n_estimators=200, xgb_model__max_depth=40, xgb_model__learning_rate=0.3, xgb_model__gamma=1.5, selector__k=85000, total= 2.8min\n",
      "[CV] xgb_model__n_estimators=200, xgb_model__max_depth=40, xgb_model__learning_rate=0.3, xgb_model__gamma=1.5, selector__k=85000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  xgb_model__n_estimators=200, xgb_model__max_depth=40, xgb_model__learning_rate=0.3, xgb_model__gamma=1.5, selector__k=85000, total= 2.9min\n",
      "[CV] xgb_model__n_estimators=200, xgb_model__max_depth=40, xgb_model__learning_rate=0.3, xgb_model__gamma=1.5, selector__k=85000 \n",
      "[CV]  xgb_model__n_estimators=200, xgb_model__max_depth=40, xgb_model__learning_rate=0.3, xgb_model__gamma=1.5, selector__k=85000, total= 2.8min\n",
      "[CV] xgb_model__n_estimators=200, xgb_model__max_depth=40, xgb_model__learning_rate=0.3, xgb_model__gamma=1.5, selector__k=85000 \n",
      "[CV]  xgb_model__n_estimators=200, xgb_model__max_depth=40, xgb_model__learning_rate=0.3, xgb_model__gamma=1.5, selector__k=85000, total= 2.8min\n",
      "[CV] xgb_model__n_estimators=200, xgb_model__max_depth=30, xgb_model__learning_rate=0.2, xgb_model__gamma=1.0, selector__k=75000 \n",
      "[CV]  xgb_model__n_estimators=200, xgb_model__max_depth=30, xgb_model__learning_rate=0.2, xgb_model__gamma=1.0, selector__k=75000, total= 2.2min\n",
      "[CV] xgb_model__n_estimators=200, xgb_model__max_depth=30, xgb_model__learning_rate=0.2, xgb_model__gamma=1.0, selector__k=75000 \n",
      "[CV]  xgb_model__n_estimators=200, xgb_model__max_depth=30, xgb_model__learning_rate=0.2, xgb_model__gamma=1.0, selector__k=75000, total= 2.2min\n",
      "[CV] xgb_model__n_estimators=200, xgb_model__max_depth=30, xgb_model__learning_rate=0.2, xgb_model__gamma=1.0, selector__k=75000 \n",
      "[CV]  xgb_model__n_estimators=200, xgb_model__max_depth=30, xgb_model__learning_rate=0.2, xgb_model__gamma=1.0, selector__k=75000, total= 2.2min\n",
      "[CV] xgb_model__n_estimators=200, xgb_model__max_depth=30, xgb_model__learning_rate=0.2, xgb_model__gamma=1.0, selector__k=75000 \n",
      "[CV]  xgb_model__n_estimators=200, xgb_model__max_depth=30, xgb_model__learning_rate=0.2, xgb_model__gamma=1.0, selector__k=75000, total= 2.3min\n",
      "[CV] xgb_model__n_estimators=150, xgb_model__max_depth=30, xgb_model__learning_rate=0.4, xgb_model__gamma=1.0, selector__k=75000 \n",
      "[CV]  xgb_model__n_estimators=150, xgb_model__max_depth=30, xgb_model__learning_rate=0.4, xgb_model__gamma=1.0, selector__k=75000, total= 1.7min\n",
      "[CV] xgb_model__n_estimators=150, xgb_model__max_depth=30, xgb_model__learning_rate=0.4, xgb_model__gamma=1.0, selector__k=75000 \n",
      "[CV]  xgb_model__n_estimators=150, xgb_model__max_depth=30, xgb_model__learning_rate=0.4, xgb_model__gamma=1.0, selector__k=75000, total= 1.8min\n",
      "[CV] xgb_model__n_estimators=150, xgb_model__max_depth=30, xgb_model__learning_rate=0.4, xgb_model__gamma=1.0, selector__k=75000 \n",
      "[CV]  xgb_model__n_estimators=150, xgb_model__max_depth=30, xgb_model__learning_rate=0.4, xgb_model__gamma=1.0, selector__k=75000, total= 1.7min\n",
      "[CV] xgb_model__n_estimators=150, xgb_model__max_depth=30, xgb_model__learning_rate=0.4, xgb_model__gamma=1.0, selector__k=75000 \n",
      "[CV]  xgb_model__n_estimators=150, xgb_model__max_depth=30, xgb_model__learning_rate=0.4, xgb_model__gamma=1.0, selector__k=75000, total= 1.7min\n",
      "[CV] xgb_model__n_estimators=200, xgb_model__max_depth=40, xgb_model__learning_rate=0.2, xgb_model__gamma=1.5, selector__k=75000 \n",
      "[CV]  xgb_model__n_estimators=200, xgb_model__max_depth=40, xgb_model__learning_rate=0.2, xgb_model__gamma=1.5, selector__k=75000, total= 2.8min\n",
      "[CV] xgb_model__n_estimators=200, xgb_model__max_depth=40, xgb_model__learning_rate=0.2, xgb_model__gamma=1.5, selector__k=75000 \n",
      "[CV]  xgb_model__n_estimators=200, xgb_model__max_depth=40, xgb_model__learning_rate=0.2, xgb_model__gamma=1.5, selector__k=75000, total= 2.8min\n",
      "[CV] xgb_model__n_estimators=200, xgb_model__max_depth=40, xgb_model__learning_rate=0.2, xgb_model__gamma=1.5, selector__k=75000 \n",
      "[CV]  xgb_model__n_estimators=200, xgb_model__max_depth=40, xgb_model__learning_rate=0.2, xgb_model__gamma=1.5, selector__k=75000, total= 2.8min\n",
      "[CV] xgb_model__n_estimators=200, xgb_model__max_depth=40, xgb_model__learning_rate=0.2, xgb_model__gamma=1.5, selector__k=75000 \n",
      "[CV]  xgb_model__n_estimators=200, xgb_model__max_depth=40, xgb_model__learning_rate=0.2, xgb_model__gamma=1.5, selector__k=75000, total= 2.8min\n",
      "[CV] xgb_model__n_estimators=200, xgb_model__max_depth=30, xgb_model__learning_rate=0.4, xgb_model__gamma=1.5, selector__k=100000 \n",
      "[CV]  xgb_model__n_estimators=200, xgb_model__max_depth=30, xgb_model__learning_rate=0.4, xgb_model__gamma=1.5, selector__k=100000, total= 2.4min\n",
      "[CV] xgb_model__n_estimators=200, xgb_model__max_depth=30, xgb_model__learning_rate=0.4, xgb_model__gamma=1.5, selector__k=100000 \n",
      "[CV]  xgb_model__n_estimators=200, xgb_model__max_depth=30, xgb_model__learning_rate=0.4, xgb_model__gamma=1.5, selector__k=100000, total= 2.3min\n",
      "[CV] xgb_model__n_estimators=200, xgb_model__max_depth=30, xgb_model__learning_rate=0.4, xgb_model__gamma=1.5, selector__k=100000 \n",
      "[CV]  xgb_model__n_estimators=200, xgb_model__max_depth=30, xgb_model__learning_rate=0.4, xgb_model__gamma=1.5, selector__k=100000, total= 2.4min\n",
      "[CV] xgb_model__n_estimators=200, xgb_model__max_depth=30, xgb_model__learning_rate=0.4, xgb_model__gamma=1.5, selector__k=100000 \n",
      "[CV]  xgb_model__n_estimators=200, xgb_model__max_depth=30, xgb_model__learning_rate=0.4, xgb_model__gamma=1.5, selector__k=100000, total= 2.4min\n",
      "[CV] xgb_model__n_estimators=230, xgb_model__max_depth=30, xgb_model__learning_rate=0.3, xgb_model__gamma=1.5, selector__k=100000 \n",
      "[CV]  xgb_model__n_estimators=230, xgb_model__max_depth=30, xgb_model__learning_rate=0.3, xgb_model__gamma=1.5, selector__k=100000, total= 2.7min\n",
      "[CV] xgb_model__n_estimators=230, xgb_model__max_depth=30, xgb_model__learning_rate=0.3, xgb_model__gamma=1.5, selector__k=100000 \n",
      "[CV]  xgb_model__n_estimators=230, xgb_model__max_depth=30, xgb_model__learning_rate=0.3, xgb_model__gamma=1.5, selector__k=100000, total= 2.7min\n",
      "[CV] xgb_model__n_estimators=230, xgb_model__max_depth=30, xgb_model__learning_rate=0.3, xgb_model__gamma=1.5, selector__k=100000 \n",
      "[CV]  xgb_model__n_estimators=230, xgb_model__max_depth=30, xgb_model__learning_rate=0.3, xgb_model__gamma=1.5, selector__k=100000, total= 2.7min\n",
      "[CV] xgb_model__n_estimators=230, xgb_model__max_depth=30, xgb_model__learning_rate=0.3, xgb_model__gamma=1.5, selector__k=100000 \n",
      "[CV]  xgb_model__n_estimators=230, xgb_model__max_depth=30, xgb_model__learning_rate=0.3, xgb_model__gamma=1.5, selector__k=100000, total= 2.7min\n",
      "[CV] xgb_model__n_estimators=230, xgb_model__max_depth=20, xgb_model__learning_rate=0.4, xgb_model__gamma=0.5, selector__k=85000 \n",
      "[CV]  xgb_model__n_estimators=230, xgb_model__max_depth=20, xgb_model__learning_rate=0.4, xgb_model__gamma=0.5, selector__k=85000, total= 1.8min\n",
      "[CV] xgb_model__n_estimators=230, xgb_model__max_depth=20, xgb_model__learning_rate=0.4, xgb_model__gamma=0.5, selector__k=85000 \n",
      "[CV]  xgb_model__n_estimators=230, xgb_model__max_depth=20, xgb_model__learning_rate=0.4, xgb_model__gamma=0.5, selector__k=85000, total= 1.9min\n",
      "[CV] xgb_model__n_estimators=230, xgb_model__max_depth=20, xgb_model__learning_rate=0.4, xgb_model__gamma=0.5, selector__k=85000 \n",
      "[CV]  xgb_model__n_estimators=230, xgb_model__max_depth=20, xgb_model__learning_rate=0.4, xgb_model__gamma=0.5, selector__k=85000, total= 1.9min\n",
      "[CV] xgb_model__n_estimators=230, xgb_model__max_depth=20, xgb_model__learning_rate=0.4, xgb_model__gamma=0.5, selector__k=85000 \n",
      "[CV]  xgb_model__n_estimators=230, xgb_model__max_depth=20, xgb_model__learning_rate=0.4, xgb_model__gamma=0.5, selector__k=85000, total= 1.9min\n",
      "[CV] xgb_model__n_estimators=150, xgb_model__max_depth=30, xgb_model__learning_rate=0.3, xgb_model__gamma=1.5, selector__k=85000 \n",
      "[CV]  xgb_model__n_estimators=150, xgb_model__max_depth=30, xgb_model__learning_rate=0.3, xgb_model__gamma=1.5, selector__k=85000, total= 1.8min\n",
      "[CV] xgb_model__n_estimators=150, xgb_model__max_depth=30, xgb_model__learning_rate=0.3, xgb_model__gamma=1.5, selector__k=85000 \n",
      "[CV]  xgb_model__n_estimators=150, xgb_model__max_depth=30, xgb_model__learning_rate=0.3, xgb_model__gamma=1.5, selector__k=85000, total= 1.8min\n",
      "[CV] xgb_model__n_estimators=150, xgb_model__max_depth=30, xgb_model__learning_rate=0.3, xgb_model__gamma=1.5, selector__k=85000 \n",
      "[CV]  xgb_model__n_estimators=150, xgb_model__max_depth=30, xgb_model__learning_rate=0.3, xgb_model__gamma=1.5, selector__k=85000, total= 1.8min\n",
      "[CV] xgb_model__n_estimators=150, xgb_model__max_depth=30, xgb_model__learning_rate=0.3, xgb_model__gamma=1.5, selector__k=85000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  xgb_model__n_estimators=150, xgb_model__max_depth=30, xgb_model__learning_rate=0.3, xgb_model__gamma=1.5, selector__k=85000, total= 1.8min\n",
      "[CV] xgb_model__n_estimators=230, xgb_model__max_depth=30, xgb_model__learning_rate=0.2, xgb_model__gamma=1.0, selector__k=100000 \n",
      "[CV]  xgb_model__n_estimators=230, xgb_model__max_depth=30, xgb_model__learning_rate=0.2, xgb_model__gamma=1.0, selector__k=100000, total= 2.7min\n",
      "[CV] xgb_model__n_estimators=230, xgb_model__max_depth=30, xgb_model__learning_rate=0.2, xgb_model__gamma=1.0, selector__k=100000 \n",
      "[CV]  xgb_model__n_estimators=230, xgb_model__max_depth=30, xgb_model__learning_rate=0.2, xgb_model__gamma=1.0, selector__k=100000, total= 2.7min\n",
      "[CV] xgb_model__n_estimators=230, xgb_model__max_depth=30, xgb_model__learning_rate=0.2, xgb_model__gamma=1.0, selector__k=100000 \n",
      "[CV]  xgb_model__n_estimators=230, xgb_model__max_depth=30, xgb_model__learning_rate=0.2, xgb_model__gamma=1.0, selector__k=100000, total= 2.7min\n",
      "[CV] xgb_model__n_estimators=230, xgb_model__max_depth=30, xgb_model__learning_rate=0.2, xgb_model__gamma=1.0, selector__k=100000 \n",
      "[CV]  xgb_model__n_estimators=230, xgb_model__max_depth=30, xgb_model__learning_rate=0.2, xgb_model__gamma=1.0, selector__k=100000, total= 2.7min\n",
      "[CV] xgb_model__n_estimators=200, xgb_model__max_depth=40, xgb_model__learning_rate=0.4, xgb_model__gamma=0.5, selector__k=85000 \n",
      "[CV]  xgb_model__n_estimators=200, xgb_model__max_depth=40, xgb_model__learning_rate=0.4, xgb_model__gamma=0.5, selector__k=85000, total= 2.7min\n",
      "[CV] xgb_model__n_estimators=200, xgb_model__max_depth=40, xgb_model__learning_rate=0.4, xgb_model__gamma=0.5, selector__k=85000 \n",
      "[CV]  xgb_model__n_estimators=200, xgb_model__max_depth=40, xgb_model__learning_rate=0.4, xgb_model__gamma=0.5, selector__k=85000, total= 2.7min\n",
      "[CV] xgb_model__n_estimators=200, xgb_model__max_depth=40, xgb_model__learning_rate=0.4, xgb_model__gamma=0.5, selector__k=85000 \n",
      "[CV]  xgb_model__n_estimators=200, xgb_model__max_depth=40, xgb_model__learning_rate=0.4, xgb_model__gamma=0.5, selector__k=85000, total= 2.7min\n",
      "[CV] xgb_model__n_estimators=200, xgb_model__max_depth=40, xgb_model__learning_rate=0.4, xgb_model__gamma=0.5, selector__k=85000 \n",
      "[CV]  xgb_model__n_estimators=200, xgb_model__max_depth=40, xgb_model__learning_rate=0.4, xgb_model__gamma=0.5, selector__k=85000, total= 2.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed: 94.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 37min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=4, error_score=nan,\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('selector',\n",
       "                                              SelectKBest(k=10,\n",
       "                                                          score_func=<function chi2 at 0x00000057F2A03948>)),\n",
       "                                             ('xgb_model',\n",
       "                                              XGBClassifier(base_score=None,\n",
       "                                                            booster=None,\n",
       "                                                            colsample_bylevel=None,\n",
       "                                                            colsample_bynode=None,\n",
       "                                                            colsample_bytree=None,\n",
       "                                                            gamma=None,\n",
       "                                                            gpu_id=None,\n",
       "                                                            importance_type='gain',\n",
       "                                                            interaction_constraints=No...\n",
       "                                      verbose=False),\n",
       "                   iid='deprecated', n_iter=10, n_jobs=1,\n",
       "                   param_distributions={'selector__k': [75000, 85000, 100000],\n",
       "                                        'xgb_model__gamma': [0.5, 1.0, 1.5],\n",
       "                                        'xgb_model__learning_rate': [0.2, 0.3,\n",
       "                                                                     0.4],\n",
       "                                        'xgb_model__max_depth': [20, 30, 40],\n",
       "                                        'xgb_model__n_estimators': [150, 200,\n",
       "                                                                    230]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=12, refit=True,\n",
       "                   return_train_score=False, scoring='f1', verbose=2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "xgb_model = xgb.XGBClassifier(random_state=12)\n",
    "\n",
    "# Параметры для поиска\n",
    "param_grid = {'xgb_model__max_depth': [ 20 , 30, 40],\n",
    "              'xgb_model__learning_rate': [0.2, 0.3, 0.4 ],\n",
    "             #'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "             #'colsample_bytree': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "             #'colsample_bylevel': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "             #'min_child_weight': [0.5, 1.0, 3.0, 5.0, 7.0, 10.0],\n",
    "             'xgb_model__gamma': [ 0.5, 1.0 , 1.5],\n",
    "             #'reg_lambda': [0.1, 1.0, 5.0, 10.0, 50.0, 100.0],\n",
    "              'xgb_model__n_estimators': [150 , 200, 230] , \n",
    "             'selector__k': [ 85000 , 100000]}\n",
    "\n",
    "# Выбираем признаки, \n",
    "selector = SelectKBest(chi2)\n",
    "xgb_selected =Pipeline([('selector' , selector) , ('xgb_model' , xgb_model)])\n",
    "\n",
    "xgb_search = RandomizedSearchCV(xgb_selected, param_grid, n_iter=10,\n",
    "                            n_jobs=1, cv=4,\n",
    "                            scoring='f1', refit=True, random_state=12 , verbose = 2)\n",
    "xgb_search.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([169.28530133, 133.48721755, 104.02987111, 166.25915956,\n",
       "        141.1141153 , 159.71778071, 109.76142687, 108.26111525,\n",
       "        160.37599659, 161.30915689]),\n",
       " 'std_fit_time': array([2.19791864, 0.6869647 , 0.66620717, 0.56689652, 1.23047244,\n",
       "        0.81389509, 0.82858863, 0.93497469, 0.6289265 , 0.99589152]),\n",
       " 'mean_score_time': array([0.95517582, 1.03648371, 0.94541901, 1.00946444, 0.97268838,\n",
       "        1.007213  , 1.00321007, 0.96193087, 1.07726264, 1.06375259]),\n",
       " 'std_score_time': array([0.02143385, 0.02605096, 0.00826352, 0.00414866, 0.0251275 ,\n",
       "        0.01605028, 0.01352834, 0.01461127, 0.01262836, 0.02845417]),\n",
       " 'param_xgb_model__n_estimators': masked_array(data=[200, 200, 150, 200, 200, 230, 230, 150, 230, 200],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_xgb_model__max_depth': masked_array(data=[40, 30, 30, 40, 30, 30, 20, 30, 30, 40],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_xgb_model__learning_rate': masked_array(data=[0.3, 0.2, 0.4, 0.2, 0.4, 0.3, 0.4, 0.3, 0.2, 0.4],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_xgb_model__gamma': masked_array(data=[1.5, 1.0, 1.0, 1.5, 1.5, 1.5, 0.5, 1.5, 1.0, 0.5],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_selector__k': masked_array(data=[85000, 75000, 75000, 75000, 100000, 100000, 85000,\n",
       "                    85000, 100000, 85000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'xgb_model__n_estimators': 200,\n",
       "   'xgb_model__max_depth': 40,\n",
       "   'xgb_model__learning_rate': 0.3,\n",
       "   'xgb_model__gamma': 1.5,\n",
       "   'selector__k': 85000},\n",
       "  {'xgb_model__n_estimators': 200,\n",
       "   'xgb_model__max_depth': 30,\n",
       "   'xgb_model__learning_rate': 0.2,\n",
       "   'xgb_model__gamma': 1.0,\n",
       "   'selector__k': 75000},\n",
       "  {'xgb_model__n_estimators': 150,\n",
       "   'xgb_model__max_depth': 30,\n",
       "   'xgb_model__learning_rate': 0.4,\n",
       "   'xgb_model__gamma': 1.0,\n",
       "   'selector__k': 75000},\n",
       "  {'xgb_model__n_estimators': 200,\n",
       "   'xgb_model__max_depth': 40,\n",
       "   'xgb_model__learning_rate': 0.2,\n",
       "   'xgb_model__gamma': 1.5,\n",
       "   'selector__k': 75000},\n",
       "  {'xgb_model__n_estimators': 200,\n",
       "   'xgb_model__max_depth': 30,\n",
       "   'xgb_model__learning_rate': 0.4,\n",
       "   'xgb_model__gamma': 1.5,\n",
       "   'selector__k': 100000},\n",
       "  {'xgb_model__n_estimators': 230,\n",
       "   'xgb_model__max_depth': 30,\n",
       "   'xgb_model__learning_rate': 0.3,\n",
       "   'xgb_model__gamma': 1.5,\n",
       "   'selector__k': 100000},\n",
       "  {'xgb_model__n_estimators': 230,\n",
       "   'xgb_model__max_depth': 20,\n",
       "   'xgb_model__learning_rate': 0.4,\n",
       "   'xgb_model__gamma': 0.5,\n",
       "   'selector__k': 85000},\n",
       "  {'xgb_model__n_estimators': 150,\n",
       "   'xgb_model__max_depth': 30,\n",
       "   'xgb_model__learning_rate': 0.3,\n",
       "   'xgb_model__gamma': 1.5,\n",
       "   'selector__k': 85000},\n",
       "  {'xgb_model__n_estimators': 230,\n",
       "   'xgb_model__max_depth': 30,\n",
       "   'xgb_model__learning_rate': 0.2,\n",
       "   'xgb_model__gamma': 1.0,\n",
       "   'selector__k': 100000},\n",
       "  {'xgb_model__n_estimators': 200,\n",
       "   'xgb_model__max_depth': 40,\n",
       "   'xgb_model__learning_rate': 0.4,\n",
       "   'xgb_model__gamma': 0.5,\n",
       "   'selector__k': 85000}],\n",
       " 'split0_test_score': array([0.74782199, 0.74741298, 0.74708896, 0.7515323 , 0.74414246,\n",
       "        0.75088215, 0.74959236, 0.75122406, 0.75135262, 0.7442076 ]),\n",
       " 'split1_test_score': array([0.75557621, 0.75911731, 0.75935335, 0.75639238, 0.7592081 ,\n",
       "        0.76210331, 0.759447  , 0.75709632, 0.76062224, 0.75612009]),\n",
       " 'split2_test_score': array([0.76951673, 0.76201641, 0.76493839, 0.76480225, 0.76201587,\n",
       "        0.76548983, 0.76573021, 0.76661226, 0.76858345, 0.76042632]),\n",
       " 'split3_test_score': array([0.77483751, 0.77195434, 0.7711178 , 0.77330853, 0.76962378,\n",
       "        0.76800375, 0.7752473 , 0.77648157, 0.76836687, 0.76642841]),\n",
       " 'mean_test_score': array([0.76193811, 0.76012526, 0.76062462, 0.76150886, 0.75874755,\n",
       "        0.76161976, 0.76250422, 0.76285355, 0.7622313 , 0.7567956 ]),\n",
       " 'std_test_score': array([0.01076532, 0.00874817, 0.00885361, 0.00830345, 0.00925331,\n",
       "        0.00654337, 0.00933884, 0.00959481, 0.00705212, 0.00813768]),\n",
       " 'rank_test_score': array([ 4,  8,  7,  6,  9,  5,  2,  1,  3, 10])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры:\n",
      "{'xgb_model__n_estimators': 150, 'xgb_model__max_depth': 30, 'xgb_model__learning_rate': 0.3, 'xgb_model__gamma': 1.5, 'selector__k': 85000}\n",
      "\n",
      "Лучший F1:\n",
      "0.7628535543127094\n"
     ]
    }
   ],
   "source": [
    "print(\"Лучшие параметры:\")\n",
    "print(xgb_search.best_params_ )\n",
    "print()\n",
    "\n",
    "print(\"Лучший F1:\")\n",
    "print(xgb_search .best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgboost_tuned.joblib']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Сохраняем лучшую модель и лучшие параметры\n",
    "best_xgb_model = xgb_search.best_estimator_\n",
    "\n",
    "best_xgb_params = xgb_search.best_params_\n",
    "\n",
    "dump(best_xgb_model , 'xgboost_tuned.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем значения на тестовых данных на лучшей модели\n",
    "y_pred = best_lr_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression Test, F1: 0.7433995053806564\n"
     ]
    }
   ],
   "source": [
    "print('Logistic regression Test, F1:', f1_score(y_test , y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем значения на тестовых данных на лучшей модели\n",
    "y_pred = best_xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Test, F1-score: 0.7727005952880021\n"
     ]
    }
   ],
   "source": [
    "print('XGBoost Test, F1-score:', f1_score(y_test , y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Текст датасета лемматизирован библотекой spacy. С помощью регульрных выражений в строках оставлены только буквы и слова.\n",
    "- После лемматизации корпус текста преобразован в матрицу со значениями TfIdf. Для создания признаков были ипользованы униграммы, биграммы и триграммы. В дальнейшем будут отобраны лучшие признаки.\n",
    "- Для моделирования применены Logistic Regression и XFBoost. Рандомизированным поиском были определены оптимальные параметры моделей, а также оптимальное количество признаков. \n",
    "- На кроссвалидации с поиском параметров лучшие значения показала модель XGBoost с результатом F1-score 0.763\n",
    "- На тесте лучшие значения также показала модель XGBoost F1-score 0.773"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [x]  Весь код выполняется без ошибок\n",
    "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [x]  Данные загружены и подготовлены\n",
    "- [x]  Модели обучены\n",
    "- [x]  Значение метрики *F1* не меньше 0.75\n",
    "- [x]  Выводы написаны"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
